# PandaFactor 行情数据更新机制文档

## 概述

PandaFactor项目实现了自动化的行情数据更新机制，通过定时任务从多个数据源获取股票行情数据，经过清洗处理后存储到MongoDB数据库中。本文档详细介绍了行情数据更新的完整流程和实现机制。

## 1. 系统架构

### 1.1 整体架构图

```
┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐
│   数据源        │    │   数据清洗器     │    │   MongoDB       │
│                 │    │                  │    │                 │
│ ┌─────────────┐ │    │ ┌──────────────┐ │    │ ┌─────────────┐ │
│ │  Tushare    │ │    │ │  TS Cleaner  │ │    │ │stock_market │ │
│ └─────────────┘ │    │ └──────────────┘ │    │ └─────────────┘ │
│                 │    │                  │    │                 │
│ ┌─────────────┐ │    │ ┌──────────────┐ │    │ ┌─────────────┐ │
│ │ RiceQuant   │ │    │ │  RQ Cleaner  │ │    │ │   stocks    │ │
│ └─────────────┘ │    │ └──────────────┘ │    │ └─────────────┘ │
│                 │    │                  │    │                 │
│ ┌─────────────┐ │    │ ┌──────────────┐ │    │ ┌─────────────┐ │
│ │  XTQuant    │ │    │ │  XT Cleaner  │ │    │ │factor_base  │ │
│ └─────────────┘ │    │ └──────────────┘ │    │ └─────────────┘ │
└─────────────────┘    └──────────────────┘    └─────────────────┘
         │                       │                       │
         └───────────────────────┼───────────────────────┘
                                 │
                    ┌──────────────────┐
                    │  任务调度器      │
                    │                  │
                    │ ┌──────────────┐ │
                    │ │DataScheduler │ │
                    │ └──────────────┘ │
                    │                  │
                    │ ┌──────────────┐ │
                    │ │FactorScheduler│ │
                    │ └──────────────┘ │
                    └──────────────────┘
```

### 1.2 核心组件

| 组件 | 功能 | 文件位置 |
|------|------|---------|
| `SchedulerManager` | 调度器管理器 | `panda_data_hub/_main_auto_.py` |
| `DataScheduler` | 数据更新调度器 | `panda_data_hub/task/data_scheduler.py` |
| `FactorCleanerScheduler` | 因子清洗调度器 | `panda_data_hub/task/factor_clean_scheduler.py` |
| `TSStockMarketCleaner` | Tushare行情清洗器 | `panda_data_hub/data/tushare_stock_market_cleaner.py` |
| `RQStockMarketCleaner` | RiceQuant行情清洗器 | `panda_data_hub/data/ricequant_stock_market_cleaner.py` |
| `XTStockMarketCleaner` | XTQuant行情清洗器 | `panda_data_hub/data/xtquant_stock_market_cleaner.py` |

## 2. 调度机制

### 2.1 启动流程

```python
# 主启动文件
if __name__ == "__main__":
    # 注册信号处理器
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    try:
        # 创建并启动数据调度器
        manager.data_scheduler = DataScheduler()
        manager.data_scheduler.schedule_data()
        
        # 创建并启动因子调度器
        manager.factor_scheduler = FactorCleanerScheduler()
        manager.factor_scheduler.schedule_data()
        
        # 保持运行
        while True:
            time.sleep(1)
    except Exception as e:
        logger.error(f"Error starting scheduler: {str(e)}")
```

### 2.2 定时任务配置

```yaml
# 配置文件 (config.yaml)
# 股票数据更新时间(每日)
STOCKS_UPDATE_TIME: "20:00"
# 因子数据更新时间(每日)
FACTOR_UPDATE_TIME: "20:30"
```

### 2.3 Cron触发器

```python
def schedule_data(self):
    time = self.config["STOCKS_UPDATE_TIME"]
    hour, minute = time.split(":")
    trigger = CronTrigger(
        minute=minute,
        hour=hour,
        day='*',
        month='*',
        day_of_week='*'
    )
    
    # 添加定时任务
    self.scheduler.add_job(
        self._process_data,
        trigger=trigger,
        id=f"data_{datetime.datetime.now().strftime('%Y%m%d')}",
        replace_existing=True
    )
```

## 3. 数据源支持

### 3.1 支持的数据源

| 数据源 | 配置标识 | 认证方式 | 状态 |
|--------|----------|----------|------|
| Tushare | `tushare` | Token | ✅ 活跃 |
| RiceQuant | `ricequant` | 用户名/密码 | ✅ 活跃 |
| XTQuant | `xuntou` | Token | 🔄 开发中 |

### 3.2 数据源配置

```yaml
# 数据源选择
DATASOURCE: tqsdk
DATAHUBSOURCE: ""

# Tushare配置
TS_TOKEN: "your_tushare_token"

# RiceQuant配置
MUSER: "your_username"
MPASSWORD: "your_password"

# XTQuant配置
XT_TOKEN: "your_xt_token"
```

## 4. 数据清洗流程

### 4.1 交易日判断

所有数据清洗器首先判断当前日期是否为交易日：

```python
def is_trading_day(self, date):
    """判断传入的日期是否为股票交易日"""
    try:
        # Tushare方式
        cal_df = self.pro.query('trade_cal',
                                exchange='SSE',
                                start_date=date.replace('-', ''),
                                end_date=date.replace('-', ''))
        return not cal_df.empty and cal_df.iloc[0]['is_open'] == 1
        
        # RiceQuant方式
        trading_days = rqdatac.get_trading_dates(
            start_date=date,
            end_date=date
        )
        return len(trading_days) > 0
    except Exception as e:
        logger.error(f"检查交易日失败 {date}: {str(e)}")
        return False
```

### 4.2 数据获取流程

#### 4.2.1 Tushare数据获取

```python
def clean_meta_market_data(self, date_str):
    try:
        # 获取当日股票历史行情
        price_data = self.pro.query('daily', trade_date=date)
        
        # 获取指数成分股
        hs_300 = self.pro.query('index_weight', index_code='399300.SZ', 
                               start_date=mid_date, end_date=last_date)
        zz_500 = self.pro.query('index_weight', index_code='000905.SH', 
                               start_date=mid_date, end_date=last_date)
        zz_1000 = self.pro.query('index_weight', index_code='000852.SH', 
                                start_date=mid_date, end_date=last_date)
        
        # 数据清洗和转换
        price_data = self.clean_and_transform_data(price_data, hs_300, zz_500, zz_1000)
        
        # 批量写入数据库
        self.batch_upsert_to_mongodb(price_data)
    except Exception as e:
        logger.error(f"数据清洗失败: {str(e)}")
```

#### 4.2.2 RiceQuant数据获取

```python
def clean_meta_market_data(self, date_str):
    try:
        # 获取所有股票代码
        symbol_list = rqdatac.all_instruments(type='CS', market='cn', date=None)
        
        # 获取历史行情数据
        price_data = rqdatac.get_price(
            order_book_ids=symbol_list['order_book_id'].tolist(),
            start_date=date_str,
            end_date=date_str,
            adjust_type='none'
        )
        
        # 获取指数成分股
        self.get_index_components(start_date=date_str, end_date=date_str)
        
        # 数据清洗和转换
        merged_data = self.clean_and_transform_data(price_data, symbol_list)
        
        # 批量写入数据库
        self.batch_upsert_to_mongodb(merged_data)
    except Exception as e:
        logger.error(f"数据清洗失败: {str(e)}")
```

### 4.3 数据清洗和转换

#### 4.3.1 字段映射

| 原始字段 | 目标字段 | 转换规则 |
|---------|---------|---------|
| `trade_date` | `date` | 格式化为YYYYMMDD |
| `ts_code`/`order_book_id` | `symbol` | 添加交易所后缀 |
| `vol` | `volume` | 乘以100（手转换为股） |
| `prev_close` | `pre_close` | 字段重命名 |
| `symbol` | `name` | 字段重命名 |

#### 4.3.2 指数成分股标记

```python
def clean_index_components(self, date, data_symbol, hs_300, zz_500, zz_1000):
    """标记指数成分股"""
    try:
        if data_symbol in hs_300['con_code'].values:
            return '100'  # 沪深300
        elif data_symbol in zz_500['con_code'].values:
            return '010'  # 中证500
        elif data_symbol in zz_1000['con_code'].values:
            return '001'  # 中证1000
        else:
            return '000'  # 非成分股
    except Exception as e:
        logger.error(f"指数成分股标记失败: {str(e)}")
        return None
```

#### 4.3.3 涨跌停价格计算

```python
def calculate_upper_limit(stock_code, prev_close, stock_name):
    """计算涨停价格"""
    if 'ST' in stock_name or '*ST' in stock_name:
        return round(prev_close * 1.05, 2)  # ST股票涨跌幅限制5%
    else:
        return round(prev_close * 1.10, 2)  # 普通股票涨跌幅限制10%

def calculate_lower_limit(stock_code, prev_close, stock_name):
    """计算跌停价格"""
    if 'ST' in stock_name or '*ST' in stock_name:
        return round(prev_close * 0.95, 2)  # ST股票跌跌幅限制5%
    else:
        return round(prev_close * 0.90, 2)  # 普通股票跌跌幅限制10%
```

### 4.4 数据存储

#### 4.4.1 批量更新操作

```python
def batch_upsert_to_mongodb(self, price_data):
    """批量更新到MongoDB"""
    ensure_collection_and_indexes("stock_market")
    
    upsert_operations = []
    for record in price_data.to_dict('records'):
        upsert_operations.append(UpdateOne(
            {'date': record['date'], 'symbol': record['symbol']},
            {'$set': record},
            upsert=True
        ))
    
    if upsert_operations:
        self.db_handler.mongo_client[self.config["MONGO_DB"]]['stock_market'].bulk_write(
            upsert_operations)
        logger.info(f"成功更新市场数据: {len(upsert_operations)} 条记录")
```

#### 4.4.2 数据库集合结构

```javascript
// stock_market集合结构
{
  "_id": ObjectId,
  "date": "20240320",        // 交易日期
  "symbol": "000001.SZ",     // 股票代码
  "open": 10.50,             // 开盘价
  "high": 10.80,             // 最高价
  "low": 10.40,              // 最低价
  "close": 10.75,            // 收盘价
  "volume": 1000000,         // 成交量（股）
  "pre_close": 10.45,        // 前收盘价
  "limit_up": 11.50,         // 涨停价
  "limit_down": 9.40,        // 跌停价
  "index_component": "100",  // 指数成分股标记
  "name": "平安银行"          // 股票名称
}
```

## 5. 股票基础信息更新

### 5.1 股票元数据清洗

```python
def clean_metadata(self):
    """清洗股票基础信息"""
    try:
        # 获取股票基本信息
        stocks = self.pro.query('stock_basic')
        stocks = stocks[['ts_code', 'name']]
        stocks = stocks[stocks["name"] != "UNKNOWN"]
        
        # 字段转换
        stocks['symbol'] = stocks['ts_code'].apply(get_exchange_suffix)
        stocks = stocks.drop(columns=['ts_code'])
        stocks['expired'] = False
        
        # 清空并重新插入
        self.db_handler.mongo_delete(self.config["MONGO_DB"], 'stocks', {})
        self.db_handler.mongo_insert_many(
            self.config["MONGO_DB"],
            'stocks',
            stocks.to_dict('records')
        )
    except Exception as e:
        logger.error(f"股票元数据清洗失败: {str(e)}")
```

### 5.2 stocks集合结构

```javascript
// stocks集合结构
{
  "_id": ObjectId,
  "symbol": "000001.SZ",     // 股票代码
  "name": "平安银行",         // 股票名称
  "expired": false           // 是否退市
}
```

## 6. 错误处理和监控

### 6.1 异常处理机制

```python
def _process_data(self):
    """处理数据清洗和入库"""
    logger.info(f"开始处理数据更新")
    try:
        data_source = config['DATAHUBSOURCE']
        if data_source == 'ricequant':
            # RiceQuant数据处理
            stocks_cleaner = RQStockCleaner(self.config)
            stocks_cleaner.clean_metadata()
            stock_market_cleaner = RQStockMarketCleaner(self.config)
            stock_market_cleaner.stock_market_clean_daily()
        elif data_source == 'tushare':
            # Tushare数据处理
            stocks_cleaner = TSStockCleaner(self.config)
            stocks_cleaner.clean_metadata()
            stock_market_cleaner = TSStockMarketCleaner(self.config)
            stock_market_cleaner.stock_market_clean_daily()
    except Exception as e:
        logger.error(f"数据处理错误: {str(e)}")
```

### 6.2 日志记录

```python
# 日志配置示例
logger.info("开始市场数据清洗")
logger.info(f"成功更新市场数据: {len(upsert_operations)} 条记录")
logger.error(f"数据清洗失败: {str(e)}")
logger.warning(f"跳过非交易日: {date_str}")
```

### 6.3 性能监控

```python
# 查询性能监控
start_time = time.time()
records = db_handler.mongo_find(db_name, collection_name, query)
logger.info(f"查询耗时: {time.time() - start_time:.3f} 秒")
```

## 7. 部署和运维

### 7.1 服务启动

```bash
# 启动数据更新服务
python -m panda_data_hub

# 或者使用主程序
python panda_data_hub/_main_auto_.py
```

### 7.2 服务管理

```python
# 信号处理
def signal_handler(signum, frame):
    logger.info("收到关闭信号，停止调度器...")
    manager.stop()
    sys.exit(0)

# 优雅停止
def stop(self):
    """停止调度器"""
    self.scheduler.shutdown()
```

### 7.3 配置热更新

```python
def reload_schedule(self):
    """重新加载定时任务"""
    self.scheduler.remove_all_jobs()
    self.schedule_data()
    logger.info("定时任务重新加载完成")
```

## 8. 最佳实践

### 8.1 数据质量保证

1. **交易日验证**: 只有交易日才执行数据更新
2. **数据去重**: 使用upsert操作避免重复数据
3. **字段验证**: 检查关键字段的有效性
4. **异常过滤**: 过滤掉无效的股票数据

### 8.2 性能优化

1. **批量操作**: 使用bulk_write提升写入性能
2. **索引优化**: 在date和symbol字段上建立复合索引
3. **连接复用**: 使用单例模式管理数据库连接
4. **分批处理**: 大数据量分批处理避免内存溢出

### 8.3 监控告警

1. **日志监控**: 监控错误日志和性能日志
2. **数据完整性**: 定期检查数据的完整性和一致性
3. **服务可用性**: 监控调度服务的运行状态
4. **数据源状态**: 监控各数据源的可用性

## 9. 故障排除

### 9.1 常见问题

| 问题 | 原因 | 解决方案 |
|------|------|---------|
| 数据更新失败 | 网络连接问题 | 检查网络连接和数据源状态 |
| 数据重复 | upsert条件错误 | 检查复合键的唯一性 |
| 性能缓慢 | 索引缺失 | 检查数据库索引 |
| 内存溢出 | 数据量过大 | 分批处理数据 |

### 9.2 调试工具

```python
# 查看任务状态
scheduler.get_jobs()

# 查看执行历史
scheduler.print_jobs()

# 手动执行任务
scheduler.modify_job(job_id, next_run_time=datetime.now())
```

## 10. 扩展开发

### 10.1 新增数据源

1. 实现数据清洗器基类
2. 添加数据源配置
3. 在调度器中添加数据源分支
4. 测试数据获取和清洗功能

### 10.2 新增数据字段

1. 修改数据清洗逻辑
2. 更新数据库集合结构
3. 调整索引设计
4. 更新相关查询逻辑

## 11. 从0开始数据更新脚本

### 11.1 核心脚本功能

PandaFactor项目**确实带有从0开始更新数据的完整脚本**，主要包括：

#### 11.1.1 历史数据回填API
- **股票行情数据更新**:
  - **API路径**: `/datahub/api/v1/upsert_stockmarket_final`
  - **参数**: `start_date`, `end_date`
  - **功能**: 支持指定日期范围的全量历史数据更新

- **因子数据更新**:
  - **API路径**: `/datahub/api/v1/upsert_factor_final`
  - **参数**: `start_date`, `end_date`
  - **功能**: 支持指定日期范围的因子数据全量更新

#### 11.1.2 数据库初始化脚本
- **索引创建脚本**: `panda_data/scripts/create_indexes.py`
  - 为MongoDB创建必要的数据库索引
  - 启动方式: `python panda_data/panda_data/scripts/create_indexes.py`

- **数据库优化脚本**: `panda_data/scripts/optimize_mongodb.py`
  - 优化MongoDB性能，支持分区和索引重建
  - 启动方式: `python panda_data/panda_data/scripts/optimize_mongodb.py --rebuild-indexes --create-partitions`

#### 11.1.3 自动调度服务
- **主调度器**: `panda_data_hub/_main_auto_.py`
  - 每日定时更新数据（默认20:00执行）
  - 启动方式: `python -m panda_data_hub`

### 11.2 从0开始数据更新的完整流程

#### 方式1：使用Web API（推荐）
```bash
# 1. 启动服务器
python -m panda_factor_server  # 启动在8111端口

# 2. 调用API全量更新历史数据（例如2020-2024年）
curl "http://localhost:8111/datahub/api/v1/upsert_stockmarket_final?start_date=20200101&end_date=20241231"

# 3. 更新因子数据
curl "http://localhost:8111/datahub/api/v1/upsert_factor_final?start_date=20200101&end_date=20241231"

# 4. 查看更新进度
curl "http://localhost:8111/datahub/api/v1/get_progress_stock_final"
curl "http://localhost:8111/datahub/api/v1/get_progress_factor_final"
```

#### 方式2：直接使用服务类
```python
from panda_data_hub.services.ts_stock_market_clean_service import StockMarketCleanTSServicePRO
from panda_common.config import config

# 初始化服务
service = StockMarketCleanTSServicePRO(config)

# 执行历史数据清洗
service.stock_market_history_clean("20200101", "20241231")
```

### 11.3 数据初始化步骤

1. **环境准备**:
   - 安装MongoDB并启动服务
   - 配置 `panda_common/panda_common/config.yaml`
   - 设置数据源Token（Tushare/RiceQuant）

2. **创建数据库索引**:
```bash
python panda_data/panda_data/scripts/create_indexes.py
```

3. **全量数据更新**:
```bash
# 启动服务器
python -m panda_factor_server

# 通过API或直接调用服务更新数据
```

4. **验证数据**:
```python
import panda_data
panda_data.init()

# 检查数据是否存在
market_data = panda_data.get_market_data("20240101", "20240110")
print(f"获取到 {len(market_data)} 条行情数据")
```

### 11.4 注意事项

1. **数据源限制**: Tushare有API调用频率限制，大量历史数据更新需要较长时间
2. **存储空间**: 全量历史数据需要较大存储空间（建议50GB+）
3. **网络稳定**: 长时间数据更新需要稳定的网络连接
4. **进度监控**: 使用API的进度查询功能监控更新状态

## 总结

PandaFactor的行情数据更新机制通过自动化调度、多数据源支持、数据清洗和质量保证，实现了可靠的行情数据更新。系统具有良好的扩展性和可维护性，能够满足量化投资对数据质量和实时性的要求。

**特别说明**: PandaFactor项目**提供了完整的从0开始数据更新解决方案**，包括历史数据回填、数据库初始化、多数据源支持和进度监控等功能，可以满足从零开始构建完整历史数据库的需求。